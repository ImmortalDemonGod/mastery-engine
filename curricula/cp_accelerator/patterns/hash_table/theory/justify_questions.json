[
  {
    "id": "two_sum_hash_table_advantage",
    "question": "Explain why using a hash table is superior to a nested loop approach for the Two Sum problem. What is the fundamental advantage that makes this optimization possible?",
    "model_answer": "**Why hash tables are superior:**\n\n1. **Nested loops (brute force): O(n²) time**\n   - For each element nums[i], scan entire array to find target - nums[i]\n   - Results in n × n = n² comparisons\n   - Example: For n=10,000, requires 100,000,000 comparisons\n\n2. **Hash table approach: O(n) time**\n   - For each element nums[i], check if complement (target - nums[i]) exists in hash table\n   - Hash table lookup is O(1) average case\n   - Results in n lookups, each O(1) = O(n) total\n   - Example: For n=10,000, requires only 10,000 operations (10,000× faster)\n\n**The fundamental insight:**\n- We trade space for time by storing elements we've seen\n- Instead of re-scanning the array, we do a constant-time lookup\n- The hash table acts as a \"memory\" of past elements, eliminating redundant work\n\n**Key enabling property:**\n- The complement relationship is symmetric: if a + b = target, then b = target - a\n- We only need to remember past elements and their indices\n- When we see element x, we check if (target - x) was seen before\n\nThis is a classic example of using extra space (O(n) for the hash table) to dramatically reduce time complexity from O(n²) to O(n).",
    "failure_modes": [
      {
        "category": "Vague Hand-Waving",
        "keywords": [
          "faster",
          "stores things",
          "remembers"
        ],
        "feedback": "You're right that hash tables are faster, but *why*? What specific operation does a hash table make O(1) that would otherwise be O(n)?"
      },
      {
        "category": "Missing Complexity Analysis",
        "keywords": [
          "hash table",
          "lookup"
        ],
        "feedback": "You've identified hash tables enable fast lookups, but can you quantify this? What's the time complexity of both approaches, and how do they compare for large n?"
      },
      {
        "category": "No Space-Time Tradeoff",
        "keywords": [
          "O(n)",
          "linear"
        ],
        "feedback": "Good analysis of time complexity! But what about space? The hash table approach uses O(n) extra space—is this tradeoff worth it?"
      }
    ]
  },
  {
    "id": "two_sum_complexity",
    "question": "Analyze the time and space complexity of the optimal Two Sum solution. Why is the hash table approach asymptotically optimal, and what assumptions does this rely on?",
    "model_answer": "**Time Complexity: O(n)**\n- Single pass through the array (n elements)\n- For each element:\n  * Compute complement: O(1) arithmetic\n  * Hash table lookup: O(1) average case\n  * Hash table insertion: O(1) average case\n- Total: n × O(1) = O(n)\n\n**Space Complexity: O(n)**\n- Hash table stores at most n elements (worst case: no solution found until the end)\n- Each entry stores: key (number) + value (index)\n- In Python, dict has some overhead, but still O(n)\n\n**Why is this optimal?**\n- We must examine every element at least once to find the pair\n- Therefore, O(n) is the lower bound for time complexity\n- The hash table achieves this lower bound\n- Any algorithm faster than O(n) is impossible (we might miss the solution)\n\n**Critical assumptions:**\n1. **Hash table lookups are O(1) average case**\n   - True for good hash functions with low collision rates\n   - Worst case is O(n) if all elements hash to same bucket (extremely rare)\n   - Amortized analysis: over many operations, O(1) holds\n\n2. **Problem guarantees exactly one solution**\n   - If no solution existed, we'd still need O(n) to verify\n   - Multiple solutions wouldn't change complexity\n\n3. **Numbers fit in memory**\n   - If numbers are enormous (arbitrary precision), hashing cost increases\n   - For typical int/float, hashing is constant time\n\n**Comparison to alternatives:**\n- Brute force: O(n²) time, O(1) space\n- Sorting + two pointers: O(n log n) time, O(1) or O(n) space (depending on sort)\n- Hash table: O(n) time, O(n) space — optimal time, acceptable space\n\nFor most practical purposes, O(n) time with O(n) space is the best solution because time complexity dominates for large inputs.",
    "failure_modes": [
      {
        "category": "Only States Complexity",
        "keywords": [
          "O(n)",
          "linear"
        ],
        "feedback": "You've stated O(n), but can you explain *why*? Walk through what happens in a single pass and why hash operations are constant time."
      },
      {
        "category": "Ignores Hash Collision",
        "keywords": [
          "O(1)",
          "constant"
        ],
        "feedback": "You're right that hash lookups are typically O(1), but what about the worst case? Hash collisions can degrade to O(n) lookups. Why can we ignore this in practice?"
      },
      {
        "category": "Missing Lower Bound",
        "keywords": [
          "optimal",
          "best"
        ],
        "feedback": "You claim this is optimal, but how do you know we can't do better than O(n)? Can you prove a lower bound for this problem?"
      }
    ]
  },
  {
    "id": "two_sum_edge_cases",
    "question": "What edge cases must be handled in the Two Sum problem, and why is it critical to check that indices are different?",
    "model_answer": "**Critical edge cases:**\n\n1. **Same element used twice (the key edge case)**\n   - Example: nums = [3, 3], target = 6\n   - Correct answer: [0, 1] (two different 3s)\n   - **Why indices matter**: Problem requires two **different** elements\n   - **Bug to avoid**: When we see nums[i] = 3, and compute complement = 6 - 3 = 3,\n     we must ensure we don't return [i, i] (using same element twice)\n   - **Solution**: Only check hash table for complement **before** inserting current element,\n     OR check that seen[complement] != i\n\n2. **Duplicate numbers (but not the solution)**\n   - Example: nums = [3, 2, 3], target = 6\n   - Multiple 3s exist, but only the pair at [0, 2] is valid\n   - Hash table naturally handles this: stores only most recent index\n   - This is fine because we only need **any** valid pair\n\n3. **No solution (if problem doesn't guarantee one)**\n   - Example: nums = [1, 2, 3], target = 10\n   - Must return empty list or None (depending on specification)\n   - In LeetCode problem, this is guaranteed not to happen\n\n4. **Negative numbers**\n   - Example: nums = [-1, -2, 3], target = -3\n   - Complement: -3 - (-1) = -2, so [-1, -2] is valid\n   - Hash tables handle negative numbers naturally (no special case needed)\n\n5. **Two-element array (minimum size)**\n   - Example: nums = [2, 7], target = 9\n   - Edge case for length constraints (problem says 2 ≤ nums.length)\n   - Should work correctly without special handling\n\n**Why checking indices is critical:**\n- Problem: \"you may not use the **same element** twice\"\n- This means same **index**, not same **value**\n- If nums = [3, 2, 4], target = 6:\n  * We CAN use 3 and 3 if they're at different indices\n  * We CANNOT use nums[0] twice\n\n**Implementation implications:**\n```python\n# CORRECT: Check hash table before inserting\nfor i, num in enumerate(nums):\n    complement = target - num\n    if complement in seen:  # This ensures we don't use same index\n        return [seen[complement], i]\n    seen[num] = i  # Insert AFTER checking\n\n# WRONG: Would allow using same element\nfor i, num in enumerate(nums):\n    seen[num] = i  # Insert BEFORE checking\n    complement = target - num\n    if complement in seen:  # Could find same element!\n        return [seen[complement], i]\n```\n\nThe edge case of using the same element twice is the most subtle and commonly missed bug in Two Sum implementations.",
    "failure_modes": [
      {
        "category": "No Concrete Examples",
        "keywords": [
          "edge cases",
          "special"
        ],
        "feedback": "You've mentioned edge cases exist, but can you give specific examples? What input would break a naive implementation?"
      },
      {
        "category": "Missing Same-Index Bug",
        "keywords": [
          "duplicates",
          "same number"
        ],
        "feedback": "Good point about duplicates! But there's a more subtle edge case: what if the complement equals the current element? Can you return [i, i]?"
      },
      {
        "category": "No Implementation Detail",
        "keywords": [
          "indices",
          "different"
        ],
        "feedback": "You've identified that indices must be different, but HOW do you ensure this in code? The order of operations (check before insert vs. insert before check) matters."
      }
    ]
  }
]
